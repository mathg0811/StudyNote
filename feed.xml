<feed xmlns="http://www.w3.org/2005/Atom"> <id>http://mathg0811.github.io/</id><title>DS's Study Note</title><subtitle>Just a note to describe my recent study Begun with AI study I will follow up with my Optics research Sometime article review?</subtitle> <updated>2022-06-19T12:32:39+09:00</updated> <author> <name>Daeseong Jung</name> <uri>http://mathg0811.github.io/</uri> </author><link rel="self" type="application/atom+xml" href="http://mathg0811.github.io/feed.xml"/><link rel="alternate" type="text/html" hreflang="ko" href="http://mathg0811.github.io/"/> <generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator> <rights> © 2022 Daeseong Jung </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>RL Model Test - Deep Fake</title><link href="http://mathg0811.github.io/posts/Deep-Fake-Test/" rel="alternate" type="text/html" title="RL Model Test - Deep Fake" /><published>2022-03-23T20:00:00+09:00</published> <updated>2022-03-23T20:00:00+09:00</updated> <id>http://mathg0811.github.io/posts/Deep-Fake-Test/</id> <content src="http://mathg0811.github.io/posts/Deep-Fake-Test/" /> <author> <name>DS Jung</name> </author> <category term="RL Model Test" /> <category term="Artificial Intelligence" /> <summary> Reference : Just record for test of a Model from Nicks Video My test clip : </summary> </entry> <entry><title>ML Model Test - Movenet Multiperson</title><link href="http://mathg0811.github.io/posts/Movenet-Test/" rel="alternate" type="text/html" title="ML Model Test - Movenet Multiperson" /><published>2022-02-22T16:00:00+09:00</published> <updated>2022-06-19T12:29:07+09:00</updated> <id>http://mathg0811.github.io/posts/Movenet-Test/</id> <content src="http://mathg0811.github.io/posts/Movenet-Test/" /> <author> <name>DS Jung</name> </author> <category term="ML Model Test" /> <category term="Artificial Intelligence" /> <summary> Reference : Just record for test of a Model directly loaded from Hub My test clip : </summary> </entry> <entry><title>Review - Article Alphago Zero</title><link href="http://mathg0811.github.io/posts/Review-Alphago-Zero/" rel="alternate" type="text/html" title="Review - Article Alphago Zero" /><published>2022-02-07T16:00:00+09:00</published> <updated>2022-06-19T12:29:07+09:00</updated> <id>http://mathg0811.github.io/posts/Review-Alphago-Zero/</id> <content src="http://mathg0811.github.io/posts/Review-Alphago-Zero/" /> <author> <name>DS Jung</name> </author> <category term="Review" /> <category term="Artificial Intelligence" /> <summary> Link : 일단 읽으면서 생각 흐름대로 끄적이기부터 Alphago 이세돌을 이긴 첫번째 alphgo는 두 개의 deep neural network를 사용 Policy network : Outputs move probabilities Value network : predict the winner of games played by the policy network Train 후에는 Monte Carlo Tree Saerch (MCTS) 로 통합, 가능성이 높은 수들을 위주로 예측하고 이 예측된 수들의 승리가능성을 value network로 판단 Alphago Zero Alphago Zero는 각각 판후이와 이세돌을 이긴 Alphago Fan 과 Alphago Lee 와는 중요한... </summary> </entry> <entry><title>RLcourse note - Lecture 9 Exploration and Exploitation</title><link href="http://mathg0811.github.io/posts/RL-course-Note-9/" rel="alternate" type="text/html" title="RLcourse note - Lecture 9 Exploration and Exploitation" /><published>2022-01-14T19:00:00+09:00</published> <updated>2022-01-21T19:18:02+09:00</updated> <id>http://mathg0811.github.io/posts/RL-course-Note-9/</id> <content src="http://mathg0811.github.io/posts/RL-course-Note-9/" /> <author> <name>DS Jung</name> </author> <category term="RLcourse" /> <category term="Note" /> <summary> Video Link : 9강 소감 Exploration과 Exploitation을 밸런스를 맞추면서 학습하도록하는 몇가지 기법에 대한 내용인데 별로 중요하진 않은것같다..? 솔직히 몇가지 배웠어도 큰 성능차이가 나는 부분도 아니고 몇 가지 환경적 상황 변수를 파악하고 거기에 맞게 설계한다면 이런 문제는 훨씬 효율적이고 적합하게 해결될 수 있다. 몇개 내용설명이 미흡하여 따로 공부해볼까했지만 중요하지 않아보여서 패스 Introduction Exploration vs. Exploitation Dilemma Inline decision-making invloves a fundamental choice: Exploitation : Make the best decision g... </summary> </entry> <entry><title>RLcourse note - Lecture 8 Integrating Learning and Planning</title><link href="http://mathg0811.github.io/posts/RL-course-Note-8/" rel="alternate" type="text/html" title="RLcourse note - Lecture 8 Integrating Learning and Planning" /><published>2022-01-04T18:00:00+09:00</published> <updated>2022-01-17T21:27:24+09:00</updated> <id>http://mathg0811.github.io/posts/RL-course-Note-8/</id> <content src="http://mathg0811.github.io/posts/RL-course-Note-8/" /> <author> <name>DS Jung</name> </author> <category term="RLcourse" /> <category term="Note" /> <summary> Video Link : 8강 소감 Tree Search 의 장점은 알 수 없는 Model을 가정하여 거기에서 현재까지 학습된 policy에 따라 여러 시나리오들을 진행해보고 그를 바탕으로 Value를 빠르게 계산해볼 수 있다는 것이다. 강의에서는 Model로부터 Sample Experience를 확보하여 빠른 학습이 가능하다는 것을 중점으로 두고 설명하고 있으나, 사실 이 부분은 논리적으로 빠른 학습은 어려워 보인다. 특히 모델의 오차를 더 강화할 수도 있다는 부분에서 그렇다. 그러나 Tree Search 과정은 상당히 유의미한데, 이 방법을 통해 실제 Policy를 기반으로 유의미한 미래 예측과 그 Return 예측을 통해 Action을 선택할 수 있게 함으로써 무가치한 미래 예측에 할당될 자... </summary> </entry> </feed>
